# -*- coding: utf-8 -*-
"""
--------------------------------------------------------------------------------
PROJET      : Analyse du March√© de l'Emploi (SA√© Data)
FICHIER     : scraping.py
DESCRIPTION : Script d'extraction automatis√©e des offres d'emploi sur HelloWork.
DATE        : Janvier 2026
--------------------------------------------------------------------------------
"""

import time
import pandas as pd
import random
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By

# --- CONFIGURATION DU SCRAPING ---
OBJECTIF = 1000  # Nombre d'offres √† r√©cup√©rer
VILLE = ""  # Laisser vide pour une recherche "France Enti√®re"
NOM_FICHIER = "dataset_hellowork_v3_france.csv"


def lancer_scraping_france():
    """
    Fonction principale du robot d'extraction.
    Parcourt les pages de r√©sultats, extrait les donn√©es brutes et sauvegarde en CSV.
    """
    print(f"--- üá´üá∑ D√©marrage du scraping FRANCE ENTI√àRE : Objectif {OBJECTIF} offres ---")

    # 1. Configuration du navigateur (Chrome)
    options = webdriver.ChromeOptions()
    # options.add_argument("--headless")  # Mode sans interface graphique (activ√© en prod)
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")

    # User-Agent : Indispensable pour ne pas √™tre d√©tect√© comme un robot basique
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    # 2. Initialisation du Driver Selenium
    # Gestion automatique de la version du ChromeDriver
    try:
        driver = webdriver.Chrome(options=options)
    except Exception as e:
        print("‚ö†Ô∏è Erreur lancement driver standard, tentative avec Service...")
        driver = webdriver.Chrome(service=Service(), options=options)

    # Construction de l'URL de recherche
    url_base = f"https://www.hellowork.com/fr-fr/emploi/recherche.html?k={VILLE}"
    driver.get(url_base)

    donnees = []
    page = 1

    try:
        # Pause pour laisser le temps au JavaScript de charger
        time.sleep(2)

        # Gestion de la banni√®re Cookies (si elle appara√Æt)
        try:
            driver.find_element(By.ID, "onetrust-accept-btn-handler").click()
        except:
            pass  # On ignore si le bouton n'est pas l√†

        # --- BOUCLE PRINCIPALE ---
        while len(donnees) < OBJECTIF:
            print(f"üìÑ Page {page} | Stock : {len(donnees)} offres collect√©es")

            # R√©cup√©ration de toutes les "cartes" offres de la page courante
            cartes = driver.find_elements(By.CSS_SELECTOR, "[data-cy='serpCard']")

            if not cartes:
                print("‚ö†Ô∏è Plus d'offres trouv√©es ou blocage de s√©curit√©.")
                break

            for carte in cartes:
                try:
                    # A. Extraction Titre & Entreprise
                    # On utilise une logique robuste : parfois c'est h3, parfois des p
                    h3 = carte.find_element(By.TAG_NAME, "h3")
                    ps = h3.find_elements(By.TAG_NAME, "p")

                    if len(ps) >= 2:
                        titre = ps[0].get_attribute("textContent").strip()
                        entreprise = ps[1].get_attribute("textContent").strip()
                    else:
                        # Fallback (Plan B) si la structure HTML change
                        full_text = h3.get_attribute("textContent").strip()
                        parts = full_text.split('\n')
                        titre = parts[0].strip()
                        entreprise = parts[1].strip() if len(parts) > 1 else "Inconnu"

                    if not titre: continue

                    # B. Extraction Localisation
                    try:
                        loc = carte.find_element(By.CSS_SELECTOR, "[data-cy='localisationCard']").get_attribute(
                            "textContent").strip()
                    except:
                        loc = "France"

                    # C. Extraction Contrat
                    try:
                        contrat = carte.find_element(By.CSS_SELECTOR, "[data-cy='contractCard']").get_attribute(
                            "textContent").strip()
                    except:
                        contrat = "Non sp√©cifi√©"

                    # D. Extraction Salaire (Parsing du texte global)
                    salaire = "Non affich√©"
                    carte_text = carte.get_attribute("textContent")
                    if "‚Ç¨" in carte_text:
                        import re
                        # Regex pour trouver une s√©quence de chiffres suivie du symbole ‚Ç¨
                        match = re.search(r'([0-9\s]+‚Ç¨.*)', carte_text)
                        if match:
                            salaire = match.group(1).strip()
                        else:
                            # M√©thode ligne par ligne si la regex √©choue
                            for line in carte_text.split('\n'):
                                if "‚Ç¨" in line:
                                    salaire = line.strip()
                                    break

                    # E. Extraction Lien
                    try:
                        lien = carte.find_element(By.TAG_NAME, "a").get_attribute("href")
                    except:
                        lien = "Non disponible"

                    # Ajout au dataset
                    donnees.append({
                        "Titre": titre,
                        "Entreprise": entreprise,
                        "Localisation": loc,
                        "Contrat": contrat,
                        "Salaire": salaire,
                        "Lien": lien
                    })

                    # Arr√™t imm√©diat si l'objectif est atteint
                    if len(donnees) >= OBJECTIF: break

                except Exception as e:
                    continue  # Si une carte bugue, on passe √† la suivante

            # Passage √† la page suivante
            page += 1
            driver.get(f"{url_base}&p={page}")

            # PAUSE AL√âATOIRE : Crucial pour √©viter le blocage IP (Anti-bot)
            time.sleep(random.uniform(1.0, 2.2))

    finally:
        # Fermeture propre du navigateur dans tous les cas
        try:
            driver.quit()
        except:
            pass

    # 3. Exportation des donn√©es
    if donnees:
        df = pd.DataFrame(donnees)
        # Encodage utf-8-sig pour compatibilit√© Excel parfaite
        df.to_csv(NOM_FICHIER, index=False, encoding='utf-8-sig', sep=';')
        print(f"\n‚ú® SUCC√àS ! Fichier '{NOM_FICHIER}' g√©n√©r√© avec {len(df)} lignes.")
    else:
        print("‚ùå √âCHEC : Aucune donn√©e r√©cup√©r√©e.")


if __name__ == "__main__":
    lancer_scraping_france()